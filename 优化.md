# SEO 优化建议

本文档总结了针对“AI菜谱生成器”项目实施的SEO优化措施，并提供了未来的优化方向。

## 已实施的优化

### 1. 核心问题：连接SPA与SSR

*   **问题**: 项目最初是一个单页面应用（SPA），内容由客户端动态生成。搜索引擎难以抓取和索引由JavaScript生成的内容，导致SEO效果不佳。
*   **解决方案**: 我们将关键的菜谱展示功能与后端的服务器端渲染（SSR）页面连接起来。具体措施包括：
    *   修改了后端API（`/api/generate`），使其在生成菜谱选项时，不仅返回菜谱名称，还返回一个URL友好的“slug”。
    *   将前端的菜谱选项列表（`RecipeOptionsList.tsx`）和“每日菜谱”（`RecipeOfTheDay.tsx`）中的交互元素从`<button>`修改为`<a>`标签。
    *   使用生成的`slug`为每个`<a>`标签创建了指向对应SSR页面的`href`属性（例如`/recipes/gong-bao-ji-ding`）。
*   **效果**: 搜索引擎现在可以顺着这些链接抓取并索引每一个独立的菜谱页面，极大地提高了网站内容的可发现性。

### 2. 页面元数据优化

*   **问题**: `index.html`和SSR页面的`<title>`和`<meta name="description">`标签内容单调，未能有效吸引用户点击。
*   **解决方案**:
    *   将`index.html`的标题更新为“AI菜谱生成器 - 您的智能美食助手”，并撰写了更具吸引力的描述。
    *   为每个SSR菜谱页面动态生成了标题，格式为“【菜谱名称】 - AI菜谱生成器”。
*   **效果**: 在搜索结果中展示更相关、更吸引人的标题和摘要，有助于提高点击率。

### 3. 结构化数据 (Schema Markup)

*   **问题**: 菜谱的结构化数据（JSON-LD）中的`totalTime`字段格式不符合Google要求的ISO 8601标准。
*   **解决方案**: 在`[slug].ts`文件中添加了辅助函数，将“15分钟 + 30分钟”这样的字符串转换为`PT45M`的ISO 8601格式。
*   **效果**: 确保了Google可以正确解析菜谱的烹饪总时间，有助于在搜索结果中以富文本摘要（Rich Snippet）的形式展示菜谱，例如显示预估烹饪时间。

### 4. 图片SEO

*   **问题**: 部分图片缺少描述性的`alt`文本。
*   **解决方案**: 为`Welcome.tsx`组件中的图片添加了`alt`文本“一位正在烹饪的AI厨师”。
*   **效果**: 提高了图片的可访问性，并帮助搜索引擎理解图片内容，有可能在图片搜索中获得排名。

## 未来的优化建议

### 1. 内部链接策略

*   **建议**: 在菜谱的“制作步骤”或“描述”中，自然地链接到站内其他相关的菜谱。例如，在“红烧肉”的菜谱中，可以链接到“糖醋排骨”。
*   **理由**: 内部链接可以帮助搜索引擎发现更多页面，并传递“链接权重”，有助于提升被链接页面的排名。

### 2. 网站性能优化

*   **建议**: 使用Google PageSpeed Insights等工具分析网站加载速度，并根据建议进行优化，例如：
    *   **图片压缩**: 确保所有图片都经过压缩，减小文件大小。
    *   **代码分割**: 按需加载JavaScript，减少首屏加载时间。
    *   **浏览器缓存**: 合理配置缓存策略，加快回头客的访问速度。
*   **理由**: 网站速度是Google排名算法的重要因素之一，更快的网站能提供更好的用户体验。

### 3. 可访问性 (A11y)

*   **建议**: 确保所有交互元素（如下拉菜单、模态框等）都可以通过键盘访问，并为屏幕阅读器用户提供清晰的标签和指示。
*   **理由**: 良好的可访问性不仅是道德要求，也是Google所鼓励的。一个对所有人都友好的网站，通常也会获得更好的SEO评价。

### 4. 建立`sitemap.xml`和`robots.txt`

*   **建议**: 虽然您的项目中已有`sitemap.xml.ts`和`robots.txt.ts`，但需要确保它们：
    *   `sitemap.xml`: 动态生成并包含所有菜谱SSR页面的URL。
    *   `robots.txt`: 明确允许Googlebot抓取所有公开内容，并阻止其访问后台或非公开目录。
*   **理由**: `sitemap.xml`可以帮助搜索引擎更全面地发现您网站上的所有页面。`robots.txt`则可以指导搜索引擎的抓取行为，避免浪费抓取预算。